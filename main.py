import os
import sys
import json
import random
import argparse
import traceback
from tqdm import tqdm
from utils import (
    load_data, create_question, determine_difficulty,
    process_basic_query, process_intermediate_query, process_advanced_query,
    Agent
)

# Logger class for logging to both console and file
class Logger(object):
    def __init__(self, filename):
        self.terminal = sys.stdout
        self.log = open(filename, "a")

    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)

    def flush(self):
        self.terminal.flush()
        self.log.flush()

def _atomic_json_dump(obj, path):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    tmp_path = path + ".tmp"
    with open(tmp_path, 'w') as f:
        json.dump(obj, f, indent=4)
    os.replace(tmp_path, path)

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--dataset', type=str, default='medqa')
    parser.add_argument('--model', type=str, default='gpt-4o-mini')
    parser.add_argument('--difficulty', type=str, default='adaptive')
    parser.add_argument('--num_samples', type=int, default=None)
    parser.add_argument('--seed', type=int, default=None)
    parser.add_argument('--temperature', type=float, default=0.0, help='Temperature for LLM sampling (default: 0.0)')
    args = parser.parse_args()

    # Redirect stdout to log file
    file_name = f"{args.dataset}_{args.model}_{args.difficulty}_{args.num_samples}{'_' + str(args.seed) if args.seed is not None else ''}"

    if not os.path.exists('logs'):
        os.makedirs('logs')
    sys.stdout = Logger(f"logs/{file_name}.log")

    # Output + resume paths
    output_dir = os.path.join(os.getcwd(), 'output')
    os.makedirs(output_dir, exist_ok=True)

    output_path = os.path.join(output_dir, f"{file_name}.json")
    progress_path = os.path.join('logs', f"{file_name}.progress.json")

    # Load previous results if present (resume)
    results = []
    if os.path.exists(output_path):
        try:
            with open(output_path, 'r') as f:
                results = json.load(f)
            if not isinstance(results, list):
                print(f"[WARN] Existing output is not a list. Starting fresh: {output_path}")
                results = []
        except Exception as e:
            print(f"[WARN] Failed to load existing output ({output_path}): {e}. Starting fresh.")
            results = []

    start_no = len(results)
    if start_no > 0:
        print(f"[INFO] Resuming from sample index {start_no} (already saved {start_no} results).")

    # Keep a tiny progress file too (helpful if output gets edited)
    _atomic_json_dump({"next_index": start_no}, progress_path)

    test_qa, examplers = load_data(args.dataset)

    # Randomly select 50 test samples for quicker testing (remove this part for full eval)
    if args.seed is not None:
        random.seed(args.seed)
        
    if args.num_samples is not None and args.num_samples < len(test_qa):
        test_qa = random.sample(test_qa, args.num_samples)

    # Main loop (auto-save after each sample)
    for no, sample in enumerate(
        tqdm(test_qa[start_no:], total=len(test_qa), initial=start_no),
        start=start_no 
    ):
        if no == args.num_samples:
            break

        if no == 0:
            print(f"[INFO] no: {no}")
        else:    
            print(f"\n\n[INFO] no: {no}")

        try:
            start_api_calls = Agent.get_total_api_calls()
            question, img_path = create_question(sample, args.dataset)
            difficulty, moderator = determine_difficulty(question, args.difficulty)

            print(f"difficulty: {difficulty}")

            if difficulty == 'basic':
                final_decision = process_basic_query(question, examplers, args)
            elif difficulty == 'intermediate':
                final_decision = process_intermediate_query(question, examplers, moderator, args)
            elif difficulty == 'advanced':
                final_decision = process_advanced_query(question, args)
            else:
                raise ValueError(f"Unknown difficulty: {difficulty}")

            end_api_calls = Agent.get_total_api_calls()
            sample_api_calls = end_api_calls - start_api_calls

            if args.dataset == 'medqa':
                results.append({
                    'question': question,
                    'label': sample['answer_idx'],
                    'answer': sample['answer'],
                    'options': sample['options'],
                    'response': final_decision,
                    'difficulty': difficulty,
                    'api_calls': sample_api_calls
                })
            else:
                # Will update later for other datasets
                results.append({
                    'question': question,
                    'response': final_decision,
                    'difficulty': difficulty,
                    'api_calls': sample_api_calls
                })

            # Save after each successful sample
            _atomic_json_dump(results, output_path)
            _atomic_json_dump({"next_index": len(results)}, progress_path)
            print(f"[INFO] API calls for this sample: {sample_api_calls}")
            print(f"[INFO] Total API calls so far: {end_api_calls}")

        except KeyboardInterrupt:
            print("\n[WARN] Interrupted by user (KeyboardInterrupt). Saving progress and exiting...")
            _atomic_json_dump(results, output_path)
            _atomic_json_dump({"next_index": len(results)}, progress_path)
            break

        except Exception as e:
            print(f"\n[ERROR] Exception at sample index {no}: {type(e).__name__}: {e}")
            traceback.print_exc()
            print("[INFO] Saving progress up to last completed sample and exiting...")
            _atomic_json_dump(results, output_path)
            _atomic_json_dump({"next_index": len(results)}, progress_path)
            break

    # Final save (in case loop ends normally)
    _atomic_json_dump(results, output_path)
    _atomic_json_dump({"next_index": len(results)}, progress_path)
    print(f"[INFO] Done. Saved {len(results)} samples to: {output_path}")
    print(f"[INFO] Total API calls: {Agent.get_total_api_calls()}")

if __name__ == "__main__":
    main()